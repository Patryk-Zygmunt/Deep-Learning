{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korekta błędu w Keras po zmianie w bibliotece numpy\n",
    "import numpy as np\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# wyłączenie ostrzeżeń\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dream\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacja algorytmu DeepDream w pakiecie Keras\n",
    "\n",
    "Zaczniemy od konwolucyjnej sieci neuronowej wytrenowanej na zbiorze obrazów ImageNet. Pakiet Keras zawiera wiele takich sieci. Są to między innymi: VGG16, VGG19, Xception i ResNet50. Algorytm DeepDream może zostać zaimplementowany przy użyciu każdej z tych sieci, ale wybór sieci będzie miał oczywiście wpływ na generowane wizualizacje. Wynika to z tego, że różne architektury sieci konwolucyjnych uczą się różnych cech. W oryginalnym algorytmie DeepDream zastosowano model Inception. Wykorzystanie tego modelu pozwala na wygenerowanie ładnie wyglądających grafik, a więc skorzystamy z modelu Inception V3 dołączonego do pakietu Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "\n",
    "# Nie będziemy trenować modelu. Polecenie to wyłącza wszystkie operacje używane tylko podczas trenowania.\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Sieć Inception V3 jest budowana bez swojej konwolucyjnej bazy. \n",
    "# Model zostanie załadowany z wagami wytrenowanymi na zbiorze ImageNet.\n",
    "model = inception_v3.InceptionV3(weights='imagenet',\n",
    "                                 include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Następnie musimy zająć się obliczaniem straty — wartości, którą będziemy starali się maksymalizować w procesie wzrostu gradientu. W rozdziale 5. podczas filtrowania wizualizacji staraliśmy się maksymalizować wartość określonego filtra wybranej warstwy sieci. Tym razem będziemy jednocześnie maksymalizować aktywacje wszystkich filtrów wielu warstw, a konkretnie rzecz biorąc, będziemy maksymalizować sumę normy L2 aktywacji zbioru warstw wysokiego poziomu. Wybór warstw (a także dokładanie się poszczególnych warstw do finalnej wartości straty) ma największy wpływ na generowane wizualizacje. W związku z tym chcemy, aby parametry te można było z łatwością modyfikować. Niższe warstwy odpowiadają za wzorce geometryczne, a wyższe warstwy odpowiadają za elementy obrazu pozwalające na rozpoznawanie klas zbioru ImageNet (np. ptaków lub psów). Zaczniemy od niezbyt optymalnej konfiguracji czterech warstw, ale z pewnością warto wypróbować później działanie wielu innych konfiguracji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Słownik przypisujący nazwy warstw do współczynników wpływu aktywacji warstw \n",
    "# na wartość straty, którą chcemy maksymalizować.\n",
    "# Zauważ, że nazwy warstw są wprowadzone na stałe w wbudowanej aplikacji Inception V3. \n",
    "# Listę nazw wszystkich warstw modelu\n",
    "# można wyświetlić za pomocą polecenia model.summary().\n",
    "layer_contributions = {\n",
    "    'mixed2': 0.2,\n",
    "    'mixed3': 3.,\n",
    "    'mixed4': 2.,\n",
    "    'mixed5': 1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz czas zdefiniować tensor zawierający wartość straty: ważoną sumę normy L2 aktywacji warstw z listingu 8.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzy słownik przypisujący nazwy warstw do instancji warstw.\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# Strata będzie definiowana przez dodanie wartości charakteryzujących wpływ poszczególnych warstw na stratę.\n",
    "loss = K.variable(0.)\n",
    "for layer_name in layer_contributions:\n",
    "    # Przechwytuje wyjście warstwy.\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "\n",
    "    # Dodaje normę L2 cech warstwy do straty. Wpływ granicznych artefaktów jest pomijany poprzez określanie straty na podstawie pikseli nieznajdujących się na granicy.\n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy uruchomić proces wzrostu gradientu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W tym tensorze znajduje się wygenerowany obraz (wizja).\n",
    "dream = model.input\n",
    "\n",
    "# Oblicza gradienty wizji na podstawie wartości straty.\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "# Normalizuje gradienty (to ważny zabieg).\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "# Konfiguruje funkcję Keras służącą do uzyskiwania wartości straty i gradientów na podstawie obrazu wejściowego.\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Wartość straty', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Na koniec możemy zająć się właściwym algorytmem DeepDream. Na początku definiowana jest lista skal (określanych również mianem oktaw), które są używane podczas przetwarzania obrazów. Każda kolejna skala jest większa od poprzedniej o współczynnik równy 1,4 (jest o 40% większa) — zaczynamy od przetwarzania małego obrazu, a następnie zwiększamy jego skalę (patrz rysunek 8.4):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![proces deep dream](img\\8_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Po każdej kolejnej operacji skalowania (od najmniejszej do największej) uruchamiany jest algorytm wzrostu gradientu w celu maksymalizacji zdefiniowanej wcześniej straty przy danej skali. Po każdym zakończeniu pracy tego algorytmu skala obrazu jest zwiększana o 40%.\n",
    "\n",
    "W celu uniknięcia utraty dużej ilości szczegółów obrazu po każdej operacji skalowania (w wyniku tych operacji otrzymywany jest coraz bardziej rozmyty i rozpikselowany obraz) możemy wykonać prosty zabieg polegający na ponownym dodaniu utraconych szczegółów do obrazu. Jest to możliwe do wykonania, ponieważ wiemy, jak powinien wyglądać oryginalny obraz w większej rozdzielczości. Dysponując obrazem S o małym rozmiarze i obrazem L o większym rozmiarze, możemy przekształcić obraz L do rozmiaru obrazu S i określić różnice między tymi obrazami — różnica ta będzie określać utracone szczegóły."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kodzie algorytmu zwiększania gradientu zastosowano poniższe funkcje pomocnicze Numpy. Do prawidłowej pracy wymagają one zainstalowania biblioteki SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2],\n",
    "               1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Funkcja narzędziowa konwertująca tensor do postaci właściwego obrazu,\n",
    "    # zmiany jego rozdzielczości i zapisywania go w formie tensora, który może zostać przetworzony przez sieć Inception V3.\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Funkcja narzędziowa konwertująca tensor do formy właściwego obrazu.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zmiana kształtu obrazu (306, 458)\n",
      "...Wartość straty 0 : 1.8070966\n",
      "...Wartość straty 1 : 2.3078444\n",
      "...Wartość straty 2 : 3.0236685\n",
      "...Wartość straty 3 : 3.7816033\n",
      "...Wartość straty 4 : 4.544466\n",
      "...Wartość straty 5 : 5.263198\n",
      "...Wartość straty 6 : 5.947104\n",
      "...Wartość straty 7 : 6.566756\n",
      "...Wartość straty 8 : 7.187997\n",
      "...Wartość straty 9 : 7.7423105\n",
      "...Wartość straty 10 : 8.339379\n",
      "...Wartość straty 11 : 8.888827\n",
      "...Wartość straty 12 : 9.429738\n",
      "...Wartość straty 13 : 9.950428\n",
      "Zmiana kształtu obrazu (428, 642)\n",
      "...Wartość straty 0 : 3.0268502\n",
      "...Wartość straty 1 : 4.399698\n",
      "...Wartość straty 2 : 5.51843\n",
      "...Wartość straty 3 : 6.491634\n",
      "...Wartość straty 4 : 7.4079676\n",
      "...Wartość straty 5 : 8.236033\n",
      "...Wartość straty 6 : 8.985122\n",
      "...Wartość straty 7 : 9.711582\n",
      "Zmiana kształtu obrazu (600, 899)\n",
      "...Wartość straty 0 : 2.974997\n",
      "...Wartość straty 1 : 4.3280463\n",
      "...Wartość straty 2 : 5.48747\n",
      "...Wartość straty 3 : 6.4943824\n",
      "...Wartość straty 4 : 7.4341903\n",
      "...Wartość straty 5 : 8.304633\n",
      "...Wartość straty 6 : 9.12845\n",
      "...Wartość straty 7 : 9.912722\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import imageio\n",
    "\n",
    "# Modyfikacja tych parametrów pozwala na uzyskanie innych efektów wizualnych.\n",
    "\n",
    "step = 0.01  # Rozmiar kroku algorytmu wzrostu gradientu.\n",
    "num_octave = 3  # Liczba operacji skalowania, przy których należy uruchomić algorytm wzrostu gradientu.\n",
    "octave_scale = 1.4  # Różnica między rozmiarami kolejnych wersji obrazu.\n",
    "iterations = 20  # Liczba kroków wzrostu wykonywanych przy każdej operacji skalowania.\n",
    "\n",
    "# Jeżeli strata przekroczy wartość równą 10,\n",
    "# to proces wzrostu gradientu zostanie przerwany w celu zapobiegnięcia powstawania brzydkich artefaktów.\n",
    "max_loss = 10.\n",
    "\n",
    "# Tu należy umieścić ścieżkę obrazu, który chcemy przetwarzać.\n",
    "base_image_path = 'creative_commons_elephant.jpg'\n",
    "\n",
    "# Ładowanie obrazu do tablicy Numpy.\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "# Przygotowywanie listy krotek kształtów definiujących skalowania, \n",
    "# przy których uruchomiony zostanie algorytm wzrostu gradientu.\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "# Odwracanie listy kształtów tak, aby znalazły się one w kolejności rosnącej.\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# Zmiana rozmiaru tablicy Numpy obrazu w celu zmniejszenia jego skali.\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Zmiana kształtu obrazu', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    \n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "\n",
    "#save_img(img, fname='final_dream.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(deprocess_image(np.copy(img)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
